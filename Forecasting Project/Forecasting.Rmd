
```{r nnar_adaptive, echo=FALSE, cache=TRUE}
knitr::opts_current$set(
  dependson   = "data",  # <- the label of your data chunk
  cache.extra = list(
    file.mtime("scripts/Forecasting_functions.R"),
    file.mtime("Data/Maryland_unemployment_rate.csv"),
    1234
  )
)
set.seed(1234)
# 2) Wrap those choices; this function will be called at each step
nnar_adaptive <- function(x) {
  forecast::nnetar(x, repeats = 20)
}
start <- Sys.time()
nn_adapt_forecast <- recursive_forecast_multi(
  Maryland_ts,
  start_train = c(1980,1),
  end_train   = c(2012,12),
  model_funs  = list(nnar_adaptive),
  names       = "NNAR_adaptive",
  h = 1
)
end <- Sys.time(); end - start


nn_adapt_forecast <- nn_adapt_forecast %>%
  mutate(
    Actual_level = exp(Actual),
    NNAR_adapt_level   = exp(NNAR_adaptive),
    NNAR_adaptive_fit     = Actual_level - NNAR_adapt_level
  )
rmse_nnar_adaptive <- sqrt(mean(nn_adapt_forecast$NNAR_adaptive_fit^2))
rmse_nnar_adaptive
#add rmse_nnar to performance table
performance<-cbind(performance, rmse_nnar_adaptive)
performance
```

```{r nnar_dynamic, echo=FALSE, cache=TRUE}
knitr::opts_current$set(
  dependson   = "data",  # <- the label of your data chunk
  cache.extra = list(
    file.mtime("scripts/Forecasting_functions.R"),
    file.mtime("Data/Maryland_unemployment_rate.csv"),
    1234
  )
)
# 2) Run dynamic-window NNAR (1-year window steps, min 3y, no max cap)
start <- Sys.time()
res_dyn <- dynamic_nnar_greedy(
  ts_data     = Maryland_ts,         # your LOG series, if that's what you're using
  start_train = c(1980,1),
  end_train   = c(2012,12),
  p = 5, P = 1, size = 4, repeats = 20,
  h = 1,
  min_years   = 3,
  step_years  = 1,
  max_years   = NULL,
  lambda      = NULL,                # keep NULL if input is already logged
  name        = "NNAR_dyn"
)
end <- Sys.time(); end - start

res_dyn <- res_dyn %>%
  mutate(
    Actual_level = exp(Actual),
    NNAR_dyn_level   = exp(NNAR_dyn),
    NNAR_dyn_fit     = Actual_level - NNAR_dyn_level
  )
res_dyn<-res_dyn %>% 
  select(-time)
rmse_nnar_dyn <- sqrt(mean(res_dyn$NNAR_dyn_fit^2))
rmse_nnar_dyn
performance<-cbind(performance, rmse_nnar_dyn)
performance
```



```{r, echo=FALSE}
#attach all three NNAR forecasts to the original data for plotting
#res_dyn, nnforecast, nn_adapt_forecast, attach by actual
if (exists("all_nnar")) rm(all_nnar)

all_forecasts <- dplyr::bind_cols(
  res2              %>% dplyr::select(Auto_level,AR2_level),
  nnforecast        %>% dplyr::select(Actual_level, NNAR_fixed_level),
  nn_adapt_forecast %>% dplyr::select(NNAR_adapt_level),
  res_dyn           %>% dplyr::select(NNAR_dyn_level)
)
#make all_nnar into a ts
all_nnar <- ts(all_forecasts, start = c(2013,1), frequency = 12)
autoplot(ts(all_nnar[, c("Actual_level","NNAR_fixed_level","NNAR_adapt_level","NNAR_dyn_level")],
            start = c(2013,1), frequency = 12)) +
  labs(title = "Recursive 1-step forecasts from NNAR models",
       x = "Year", y = "Unemployment Rate") +
  theme_minimal()

```
We see that only the NNAR that was fit on the entire training window outperforms the auto arima model and AR2 model across the entire series.

```{r, echo=FALSE}
#pretty table showing the rmse for all models

performance %>%
  knitr::kable(caption = "RMSE for all models")
```
How do the models compare specifically during the covid period? From the results we see that the NNAR model that was fit on the training data that keeps the same structure throughout performs the best.

```{r, echo=FALSE}
# 0) Sanity check: same length for all forecast tables
stopifnot(
  nrow(res2) == nrow(nnforecast),
  nrow(nnforecast) == nrow(nn_adapt_forecast),
  nrow(nn_adapt_forecast) == nrow(res_dyn)
)

# 1) Bind with one Actual column + all forecast columns
all_forecasts <- dplyr::bind_cols(
  nnforecast        %>% dplyr::select(Actual_level, NNAR_fixed_level),
  nn_adapt_forecast %>% dplyr::select(NNAR_adapt_level),
  res_dyn           %>% dplyr::select(NNAR_dyn_level),
  res2              %>% dplyr::select(Auto_level, AR2_level)
)

# 2) Add a monthly index (your recursive period starts at 2013-01)
all_forecasts <- all_forecasts %>%
  mutate(t = seq(as.yearmon("2013-01"), by = 1/12, length.out = n()))

# 3) Filter the window and compute RMSEs vs Actual_level
slice_20_21 <- all_forecasts %>%
  filter(t >= as.yearmon("2020-01"), t <= as.yearmon("2021-01"))

rmse_2020_2021 <- slice_20_21 %>%
  summarise(
    NNAR_fixed = sqrt(mean((NNAR_fixed_level - Actual_level)^2, na.rm = TRUE)),
    NNAR_adapt = sqrt(mean((NNAR_adapt_level - Actual_level)^2, na.rm = TRUE)),
    NNAR_dyn   = sqrt(mean((NNAR_dyn_level   - Actual_level)^2, na.rm = TRUE)),
    autoARIMA  = sqrt(mean((Auto_level       - Actual_level)^2, na.rm = TRUE)),
    AR2        = sqrt(mean((AR2_level        - Actual_level)^2, na.rm = TRUE))
  ) %>%
  tidyr::pivot_longer(everything(), names_to = "model", values_to = "RMSE")

rmse_2020_2021
```


From this analysis we see that NNAR can be used to effectively forecast univariate time series data and the fixed model outperformed the arima models along with the adaptive and dynamic models.
